1.使用所有样本以及所有特征。
2.根据这一轮训练后的误差率来更新（1）下一轮训练时训练集各样本的权重系数和（2）本轮基学习器的投票权重。

一、工作过程
Adaboost工作过程涉及4个问题：
1）如何计算每一次训练集样本集权重？
Ans：由该训练样本本身、本轮基学习器对该样本的预测值、本轮基学习器对训练样本的整体预测误差率共同决定。
2）如何训练基模型？
Ans：默认CART决策树，∴既可以用来分类也可以用来回归。基学习器的训练与普通的单模型训练过程是完全一样的。
3）如何计算基模型的预测误差率？
Ans：分类问题：0-1损失函数。回归问题：平方损失函数或者是指数损失函数。
4）如何计算各个基学习器的投票权重？
二分类问题：投票公式是sign(求和ak·Tk(x)),ak是各分类器的权重，Tk是各分类器的预测结果。

二、多分类问题：
1.SAMME算法
    1）相似数据的分布权重，采用平等对待的方式，w=1/M
    2）利用具有权重D1的训练数据集，采用某个基本模型进行训练，得到第一个基分类器T1（x）
    3）计算基分类器T1（x）在训练集上的训练误差率e1=对i=1,M求和w1i·I（T1(xi)<>yi）
    4）按下式计算基分别器T1（x）的投!票!权!重!a1=(1/2)ln((1-e1)/e1)+ln(L-1)
    5）按下式更新第二轮训练集的权重分布。D=(w21,w22,w23...w2n)
        w2i=(w1i exp(-a1yiT1(xi)))/各项分子对i求和
    重复2——5步
    最后对样本进行一次带权重的投票，选出得票分数最大的类别cl作为最终预测类别
2.SAMME.R算法：
    